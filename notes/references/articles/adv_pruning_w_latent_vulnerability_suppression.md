# Adversarial Neural Pruning with Latent Vulnerability Suppression (2020)

## Bibliographic Information
@inproceedings{madaan2020adversarial,
  title={Adversarial neural pruning with latent vulnerability suppression},
  author={Madaan, Divyam and Shin, Jinwoo and Hwang, Sung Ju},
  booktitle={International conference on machine learning},
  pages={6575--6585},
  year={2020},
  organization={PMLR}
}

## Key Points
- Sparsification can help with robustness in the sense that fewer features can be tempered with to fool the model
- develop a concept of "Vulnerability of a latent feature": 
    - represent how much this feature is impacted by an adversary tempered input (L1-dist between this feature for a sample and its tempered version)
    - vulnerability of the network = mean of the feature's vulnerablities

- develops a "Vulnerablity Suppression loss" that aims to prevents adversarial attacks on the latent space 
- 
## Relevant Quotes
> " " 

> " " 

## Linked notes 
- [Name](path/to/note)

## To read: 
@inproceedings{ye2019adversarial,
  title={Adversarial robustness vs. model compression, or both?},
  author={Ye, Shaokai and Xu, Kaidi and Liu, Sijia and Cheng, Hao and Lambrechts, Jan-Henrik and Zhang, Huan and Zhou, Aojun and Ma, Kaisheng and Wang, Yanzhi and Lin, Xue},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={111--120},
  year={2019}
}